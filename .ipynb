{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import requests\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib  # para salvar e carregar o scaler\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "api_key = \"cul25nhr01qqav2uqppgcul25nhr01qqav2uqpq0\"\n",
    "\n",
    "url = f\"https://finnhub.io/api/v1/stock/symbol?exchange=US&token={api_key}\"\n",
    "response = requests.get(url)\n",
    "tickers_data = response.json()\n",
    "tickers = [ticker[\"symbol\"] for ticker in tickers_data]\n",
    "\n",
    "def obter_sentimento_noticias(ticker, api_key):\n",
    "    fim = int(time.time())\n",
    "    inicio = fim - (2 * 365 * 24 * 60 * 60)  # 2 anos em segundos\n",
    "\n",
    "    url = (\n",
    "        f\"https://finnhub.io/api/v1/company-news\"\n",
    "        f\"?symbol={ticker}\"\n",
    "        f\"&from={datetime.fromtimestamp(inicio).strftime('%Y-%m-%d')}\"\n",
    "        f\"&to={datetime.fromtimestamp(fim).strftime('%Y-%m-%d')}\"\n",
    "        f\"&token={api_key}\"\n",
    "    )\n",
    "\n",
    "    resp = requests.get(url)\n",
    "    noticias = resp.json()\n",
    "\n",
    "    sentimentos = []\n",
    "    for noticia in noticias:\n",
    "        if 'sentiment' in noticia and isinstance(noticia['sentiment'], dict) and 'score' in noticia['sentiment']:\n",
    "            sentimentos.append(noticia['sentiment']['score'])\n",
    "\n",
    "    if sentimentos:\n",
    "        return np.mean(sentimentos)\n",
    "    return 0.0\n",
    "\n",
    "def obter_dados_finnhub(ticker, api_key):\n",
    "    fim = datetime.now()\n",
    "    inicio = fim - timedelta(days=2*365)\n",
    "\n",
    "    df = yf.download(ticker, start=inicio.strftime('%Y-%m-%d'), end=fim.strftime('%Y-%m-%d'), auto_adjust=False)\n",
    "\n",
    "    if df.empty:\n",
    "        print(f\"‚ö†Ô∏è Aviso: dados vazios para ticker '{ticker}'. Pulando.\")\n",
    "        return None\n",
    "\n",
    "    df = df[[\"Close\"]]\n",
    "    df[\"SMA_10\"] = df[\"Close\"].rolling(window=10).mean()\n",
    "    df[\"SMA_20\"] = df[\"Close\"].rolling(window=20).mean()\n",
    "    df[\"Bollinger_Middle\"] = df[\"Close\"].rolling(window=20).mean()\n",
    "    df[\"Bollinger_STD\"] = df[\"Close\"].rolling(window=20).std()\n",
    "    df[\"Bollinger_High\"] = df[\"Bollinger_Middle\"] + 2 * df[\"Bollinger_STD\"]\n",
    "    df[\"Bollinger_Low\"] = df[\"Bollinger_Middle\"] - 2 * df[\"Bollinger_STD\"]\n",
    "\n",
    "    sentimento = obter_sentimento_noticias(ticker, api_key)\n",
    "    df[\"Sentiment\"] = sentimento\n",
    "\n",
    "    df.dropna(inplace=True)\n",
    "    return df\n",
    "\n",
    "def criar_sequencias(data, seq_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i+seq_length])\n",
    "        y.append(data[i+seq_length][0])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm1 = nn.LSTM(input_size, 100, batch_first=True)\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        self.lstm2 = nn.LSTM(100, 100, batch_first=True)\n",
    "        self.dropout2 = nn.Dropout(0.2)\n",
    "        self.fc1 = nn.Linear(100, 25)\n",
    "        self.fc2 = nn.Linear(25, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x, _ = self.lstm2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc1(x[:, -1, :])\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "modelo_path = \"modelo_lstm_multivariado.pth\"\n",
    "scaler_path = \"scaler.save\"\n",
    "scaler_close_path = \"scaler_close.save\"\n",
    "\n",
    "if os.path.exists(modelo_path) and os.path.exists(scaler_path) and os.path.exists(scaler_close_path):\n",
    "    print(f\"‚úÖ Carregando modelo e scalers salvos...\")\n",
    "    input_size = 6\n",
    "    model = LSTMModel(input_size).to(device)\n",
    "    model.load_state_dict(torch.load(modelo_path, map_location=device))\n",
    "    model.eval()\n",
    "    scaler = joblib.load(scaler_path)\n",
    "    scaler_close = joblib.load(scaler_close_path)\n",
    "else:\n",
    "    print(f\"üöÄ Treinando novo modelo...\")\n",
    "    primeiro_ticker = tickers[0]\n",
    "    df = obter_dados_finnhub(primeiro_ticker, api_key)\n",
    "\n",
    "    dados_para_modelo = df[[\"Close\", \"SMA_10\", \"SMA_20\", \"Bollinger_Low\", \"Bollinger_High\", \"Sentiment\"]].values\n",
    "\n",
    "    # scaler multivariado para todas as features\n",
    "    scaler = MinMaxScaler()\n",
    "    dados_normalizados = scaler.fit_transform(dados_para_modelo)\n",
    "    joblib.dump(scaler, scaler_path)  # salva scaler multivariado\n",
    "\n",
    "    # scaler exclusivo para Close, s√≥ para inverter previs√µes corretamente\n",
    "    scaler_close = MinMaxScaler()\n",
    "    close_values = df[[\"Close\"]].values\n",
    "    close_normalized = scaler_close.fit_transform(close_values)\n",
    "    joblib.dump(scaler_close, scaler_close_path)\n",
    "\n",
    "    seq_length = 60\n",
    "    X, y = criar_sequencias(dados_normalizados, seq_length)\n",
    "\n",
    "    X_treino = torch.tensor(X[:int(len(X)*0.75)], dtype=torch.float32).to(device)\n",
    "    y_treino = torch.tensor(y[:int(len(X)*0.75)], dtype=torch.float32).unsqueeze(1).to(device)\n",
    "    X_valid = torch.tensor(X[int(len(X)*0.75):], dtype=torch.float32).to(device)\n",
    "    y_valid = torch.tensor(y[int(len(X)*0.75):], dtype=torch.float32).unsqueeze(1).to(device)\n",
    "\n",
    "    model = LSTMModel(X.shape[2]).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    for epoch in range(50):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X_treino)\n",
    "        loss = criterion(output, y_treino)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = criterion(model(X_valid), y_valid)\n",
    "        print(f\"Epoch {epoch+1}/50 - Loss: {loss.item():.4f}, Val Loss: {val_loss.item():.4f}\")\n",
    "\n",
    "    torch.save(model.state_dict(), modelo_path)\n",
    "    print(f\"‚úÖ Modelo salvo como '{modelo_path}'!\")\n",
    "\n",
    "def prever_para_7_dias(ticker, model, seq_length=60, dias=7):\n",
    "    df = obter_dados_finnhub(ticker, api_key)\n",
    "    dados = df[[\"Close\", \"SMA_10\", \"SMA_20\", \"Bollinger_Low\", \"Bollinger_High\", \"Sentiment\"]].values\n",
    "\n",
    "    # Ajusta scaler para os dados do ticker atual\n",
    "    scaler = MinMaxScaler()\n",
    "    dados_normalizados = scaler.fit_transform(dados)\n",
    "\n",
    "    scaler_close = MinMaxScaler()\n",
    "    close_values = df[[\"Close\"]].values\n",
    "    scaler_close.fit(close_values)\n",
    "\n",
    "    input_seq = dados_normalizados[-seq_length:].copy()\n",
    "\n",
    "    previsoes_normalizadas = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for _ in range(dias):\n",
    "            X_input = torch.tensor(input_seq, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "            pred_norm = model(X_input).cpu().numpy()[0][0]\n",
    "            previsoes_normalizadas.append(pred_norm)\n",
    "\n",
    "            nova_linha = input_seq[-1].copy()\n",
    "            nova_linha[0] = pred_norm\n",
    "            input_seq = np.vstack([input_seq[1:], nova_linha])\n",
    "\n",
    "    previsoes_reais = []\n",
    "    for p in previsoes_normalizadas:\n",
    "        inv_close = scaler_close.inverse_transform([[p]])[0][0]\n",
    "        previsoes_reais.append(inv_close)\n",
    "\n",
    "    return previsoes_reais\n",
    "\n",
    "\n",
    "print(\"üìà A√ß√µes dispon√≠veis para previs√£o:\")\n",
    "for i, ticker in enumerate(tickers[:50]):\n",
    "    print(f\"{i + 1}. {ticker}\")\n",
    "\n",
    "while True:\n",
    "    ticker_escolhido = input(\"Digite o c√≥digo da a√ß√£o que deseja prever: \").upper()\n",
    "    if ticker_escolhido in tickers:\n",
    "        break\n",
    "    print(\"‚ùå C√≥digo inv√°lido! Digite um ticker da lista.\")\n",
    "\n",
    "try:\n",
    "    print(f\"üîÑ Buscando dados para {ticker_escolhido}...\")\n",
    "    df_atual = obter_dados_finnhub(ticker_escolhido, api_key)\n",
    "    valor_atual = float(df_atual[\"Close\"].iloc[-1])\n",
    "    print(f\"Valor atual da a√ß√£o {ticker_escolhido}: ${valor_atual:.2f}\")\n",
    "\n",
    "    previsoes_7_dias = prever_para_7_dias(ticker_escolhido, model)\n",
    "\n",
    "    for i, preco in enumerate(previsoes_7_dias, 1):\n",
    "        print(f\"Previs√£o para o dia {i}: ${preco:.2f}\")\n",
    "\n",
    "    previsao_df = pd.DataFrame({\n",
    "        \"Dia\": [f\"Dia {i}\" for i in range(1, len(previsoes_7_dias)+1)],\n",
    "        \"Ticker\": ticker_escolhido,\n",
    "        \"Previs√£o\": previsoes_7_dias\n",
    "    })\n",
    "\n",
    "    previsao_df.to_csv(f\"previsao_{ticker_escolhido}_7dias.csv\", index=False)\n",
    "    print(f\"‚úÖ Previs√µes salvas em 'previsao_{ticker_escolhido}_7dias.csv'!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Erro ao prever: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import requests\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib  # para salvar e carregar o scaler\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "api_key = \"cul25nhr01qqav2uqppgcul25nhr01qqav2uqpq0\"\n",
    "\n",
    "url = f\"https://finnhub.io/api/v1/stock/symbol?exchange=US&token={api_key}\"\n",
    "response = requests.get(url)\n",
    "tickers_data = response.json()\n",
    "tickers = [ticker[\"symbol\"] for ticker in tickers_data]\n",
    "\n",
    "def obter_sentimento_noticias(ticker, api_key):\n",
    "    fim = int(time.time())\n",
    "    inicio = fim - (2 * 365 * 24 * 60 * 60)  # 2 anos em segundos\n",
    "\n",
    "    url = (\n",
    "        f\"https://finnhub.io/api/v1/company-news\"\n",
    "        f\"?symbol={ticker}\"\n",
    "        f\"&from={datetime.fromtimestamp(inicio).strftime('%Y-%m-%d')}\"\n",
    "        f\"&to={datetime.fromtimestamp(fim).strftime('%Y-%m-%d')}\"\n",
    "        f\"&token={api_key}\"\n",
    "    )\n",
    "\n",
    "    resp = requests.get(url)\n",
    "    noticias = resp.json()\n",
    "\n",
    "    sentimentos = []\n",
    "    for noticia in noticias:\n",
    "        if 'sentiment' in noticia and isinstance(noticia['sentiment'], dict) and 'score' in noticia['sentiment']:\n",
    "            sentimentos.append(noticia['sentiment']['score'])\n",
    "\n",
    "    if sentimentos:\n",
    "        return np.mean(sentimentos)\n",
    "    return 0.0\n",
    "\n",
    "def obter_dados_finnhub(ticker, api_key):\n",
    "    fim = datetime.now()\n",
    "    inicio = fim - timedelta(days=2*365)\n",
    "\n",
    "    df = yf.download(ticker, start=inicio.strftime('%Y-%m-%d'), end=fim.strftime('%Y-%m-%d'), auto_adjust=False)\n",
    "\n",
    "    if df.empty:\n",
    "        print(f\"‚ö†Ô∏è Aviso: dados vazios para ticker '{ticker}'. Pulando.\")\n",
    "        return None\n",
    "\n",
    "    df = df[[\"Close\"]]\n",
    "    df[\"SMA_10\"] = df[\"Close\"].rolling(window=10).mean()\n",
    "    df[\"SMA_20\"] = df[\"Close\"].rolling(window=20).mean()\n",
    "    df[\"Bollinger_Middle\"] = df[\"Close\"].rolling(window=20).mean()\n",
    "    df[\"Bollinger_STD\"] = df[\"Close\"].rolling(window=20).std()\n",
    "    df[\"Bollinger_High\"] = df[\"Bollinger_Middle\"] + 2 * df[\"Bollinger_STD\"]\n",
    "    df[\"Bollinger_Low\"] = df[\"Bollinger_Middle\"] - 2 * df[\"Bollinger_STD\"]\n",
    "\n",
    "    sentimento = obter_sentimento_noticias(ticker, api_key)\n",
    "    df[\"Sentiment\"] = sentimento\n",
    "\n",
    "    df.dropna(inplace=True)\n",
    "    return df\n",
    "\n",
    "def criar_sequencias(data, seq_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i+seq_length])\n",
    "        y.append(data[i+seq_length][0])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm1 = nn.LSTM(input_size, 100, batch_first=True)\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        self.lstm2 = nn.LSTM(100, 100, batch_first=True)\n",
    "        self.dropout2 = nn.Dropout(0.2)\n",
    "        self.fc1 = nn.Linear(100, 25)\n",
    "        self.fc2 = nn.Linear(25, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x, _ = self.lstm2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc1(x[:, -1, :])\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "modelo_path = \"modelo_lstm_multivariado.pth\"\n",
    "scaler_path = \"scaler.save\"\n",
    "scaler_close_path = \"scaler_close.save\"\n",
    "\n",
    "if os.path.exists(modelo_path) and os.path.exists(scaler_path) and os.path.exists(scaler_close_path):\n",
    "    print(f\"‚úÖ Carregando modelo e scalers salvos...\")\n",
    "    input_size = 6\n",
    "    model = LSTMModel(input_size).to(device)\n",
    "    model.load_state_dict(torch.load(modelo_path, map_location=device))\n",
    "    model.eval()\n",
    "    scaler = joblib.load(scaler_path)\n",
    "    scaler_close = joblib.load(scaler_close_path)\n",
    "else:\n",
    "    print(f\"üöÄ Treinando novo modelo...\")\n",
    "    primeiro_ticker = tickers[0]\n",
    "    df = obter_dados_finnhub(primeiro_ticker, api_key)\n",
    "\n",
    "    dados_para_modelo = df[[\"Close\", \"SMA_10\", \"SMA_20\", \"Bollinger_Low\", \"Bollinger_High\", \"Sentiment\"]].values\n",
    "\n",
    "    # scaler multivariado para todas as features\n",
    "    scaler = MinMaxScaler()\n",
    "    dados_normalizados = scaler.fit_transform(dados_para_modelo)\n",
    "    joblib.dump(scaler, scaler_path)  # salva scaler multivariado\n",
    "\n",
    "    # scaler exclusivo para Close, s√≥ para inverter previs√µes corretamente\n",
    "    scaler_close = MinMaxScaler()\n",
    "    close_values = df[[\"Close\"]].values\n",
    "    close_normalized = scaler_close.fit_transform(close_values)\n",
    "    joblib.dump(scaler_close, scaler_close_path)\n",
    "\n",
    "    seq_length = 60\n",
    "    X, y = criar_sequencias(dados_normalizados, seq_length)\n",
    "\n",
    "    X_treino = torch.tensor(X[:int(len(X)*0.75)], dtype=torch.float32).to(device)\n",
    "    y_treino = torch.tensor(y[:int(len(X)*0.75)], dtype=torch.float32).unsqueeze(1).to(device)\n",
    "    X_valid = torch.tensor(X[int(len(X)*0.75):], dtype=torch.float32).to(device)\n",
    "    y_valid = torch.tensor(y[int(len(X)*0.75):], dtype=torch.float32).unsqueeze(1).to(device)\n",
    "\n",
    "    model = LSTMModel(X.shape[2]).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    for epoch in range(50):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X_treino)\n",
    "        loss = criterion(output, y_treino)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = criterion(model(X_valid), y_valid)\n",
    "        print(f\"Epoch {epoch+1}/50 - Loss: {loss.item():.4f}, Val Loss: {val_loss.item():.4f}\")\n",
    "\n",
    "    torch.save(model.state_dict(), modelo_path)\n",
    "    print(f\"‚úÖ Modelo salvo como '{modelo_path}'!\")\n",
    "\n",
    "def prever_para_7_dias(ticker, model, seq_length=60, dias=7):\n",
    "    df = obter_dados_finnhub(ticker, api_key)\n",
    "    dados = df[[\"Close\", \"SMA_10\", \"SMA_20\", \"Bollinger_Low\", \"Bollinger_High\", \"Sentiment\"]].values\n",
    "\n",
    "    # Ajusta scaler para os dados do ticker atual\n",
    "    scaler = MinMaxScaler()\n",
    "    dados_normalizados = scaler.fit_transform(dados)\n",
    "\n",
    "    scaler_close = MinMaxScaler()\n",
    "    close_values = df[[\"Close\"]].values\n",
    "    scaler_close.fit(close_values)\n",
    "\n",
    "    input_seq = dados_normalizados[-seq_length:].copy()\n",
    "\n",
    "    previsoes_normalizadas = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for _ in range(dias):\n",
    "            X_input = torch.tensor(input_seq, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "            pred_norm = model(X_input).cpu().numpy()[0][0]\n",
    "            previsoes_normalizadas.append(pred_norm)\n",
    "\n",
    "            nova_linha = input_seq[-1].copy()\n",
    "            nova_linha[0] = pred_norm\n",
    "            input_seq = np.vstack([input_seq[1:], nova_linha])\n",
    "\n",
    "    previsoes_reais = []\n",
    "    for p in previsoes_normalizadas:\n",
    "        inv_close = scaler_close.inverse_transform([[p]])[0][0]\n",
    "        previsoes_reais.append(inv_close)\n",
    "\n",
    "    return previsoes_reais\n",
    "\n",
    "\n",
    "print(\"üìà A√ß√µes dispon√≠veis para previs√£o:\")\n",
    "for i, ticker in enumerate(tickers[:50]):\n",
    "    print(f\"{i + 1}. {ticker}\")\n",
    "\n",
    "while True:\n",
    "    ticker_escolhido = input(\"Digite o c√≥digo da a√ß√£o que deseja prever: \").upper()\n",
    "    if ticker_escolhido in tickers:\n",
    "        break\n",
    "    print(\"‚ùå C√≥digo inv√°lido! Digite um ticker da lista.\")\n",
    "\n",
    "try:\n",
    "    print(f\"üîÑ Buscando dados para {ticker_escolhido}...\")\n",
    "    df_atual = obter_dados_finnhub(ticker_escolhido, api_key)\n",
    "    valor_atual = float(df_atual[\"Close\"].iloc[-1])\n",
    "    print(f\"Valor atual da a√ß√£o {ticker_escolhido}: ${valor_atual:.2f}\")\n",
    "\n",
    "    previsoes_7_dias = prever_para_7_dias(ticker_escolhido, model)\n",
    "\n",
    "    for i, preco in enumerate(previsoes_7_dias, 1):\n",
    "        print(f\"Previs√£o para o dia {i}: ${preco:.2f}\")\n",
    "\n",
    "    previsao_df = pd.DataFrame({\n",
    "        \"Dia\": [f\"Dia {i}\" for i in range(1, len(previsoes_7_dias)+1)],\n",
    "        \"Ticker\": ticker_escolhido,\n",
    "        \"Previs√£o\": previsoes_7_dias\n",
    "    })\n",
    "\n",
    "    previsao_df.to_csv(f\"previsao_{ticker_escolhido}_7dias.csv\", index=False)\n",
    "    print(f\"‚úÖ Previs√µes salvas em 'previsao_{ticker_escolhido}_7dias.csv'!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Erro ao prever: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
